!pip install datasets transformers torch torchvision

from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer
import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import numpy as np
from sklearn.metrics import f1_score, accuracy_score
from PIL import Image

# âœ… DÃ©finir le chemin du dataset sur Kaggle
DATASET_PATH = "/kaggle/input/animal-image-dataset-90-different-animals/animals/animals"

# âœ… Charger le modÃ¨le et le feature extractor
model_id = "google/vit-base-patch16-224-in21k"
feature_extractor = ViTFeatureExtractor.from_pretrained(model_id)

# âœ… DÃ©finir la transformation d'image (resize et normalisation)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)
])

# âœ… Charger le dataset avec ImageFolder (PyTorch dÃ©tecte les classes automatiquement)
dataset = ImageFolder(root=DATASET_PATH, transform=transform)

# âœ… Obtenir la liste des classes (animaux)
labels = dataset.classes
num_labels = len(labels)

# âœ… Diviser les donnÃ©es en train/test (80% train, 20% test)
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

# âœ… CrÃ©er un DataLoader pour l'entraÃ®nement et le test
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16)

# âœ… Charger ViT en mode multi-label classification
model = ViTForImageClassification.from_pretrained(
    model_id,
    num_labels=num_labels,
    problem_type="multi_label_classification"")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# âœ… DÃ©finir les arguments d'entraÃ®nement
training_args = TrainingArguments(
    output_dir="./vit-animals",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    evaluation_strategy="steps",
    num_train_epochs=4,
    save_steps=100,
    eval_steps=100,
    logging_steps=10,
    learning_rate=2e-4,
    save_total_limit=2,
    remove_unused_columns=False,
    push_to_hub=False,
    load_best_model_at_end=True,
)

# âœ… Fonction pour calculer les mÃ©triques
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = (logits > 0).astype(int)
    f1 = f1_score(labels, predictions, average="macro")
    acc = accuracy_score(labels, predictions)
    return {"accuracy": acc, "f1": f1}

# âœ… EntraÃ®ner avec Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
)

train_results = trainer.train()

# âœ… Sauvegarder le modÃ¨le
trainer.save_model()

# âœ… Charger le modÃ¨le sauvegardÃ©
model_path = "./vit-animals"
model = ViTForImageClassification.from_pretrained(model_path)
model.to(device)

# âœ… Fonction d'Ã©valuation
def evaluate_model(model, dataloader):
    model.eval()  # Mode Ã©valuation
    predictions = []
    true_labels = []
    
    with torch.no_grad():  # DÃ©sactive le calcul du gradient
        for batch in dataloader:
            images, labels = batch
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            logits = outputs.logits  # Obtenir les logits
            preds = (logits > 0).cpu().numpy()  # Convertir en classes (0 ou 1)

            predictions.extend(preds)
            true_labels.extend(labels.cpu().numpy())

    # Calculer la prÃ©cision et le F1-score
    acc = accuracy_score(true_labels, predictions)
    f1 = f1_score(true_labels, predictions, average="macro")
    
    print(f"ðŸ“Š PrÃ©cision : {acc:.4f}")
    print(f"ðŸ“Š F1-score : {f1:.4f}")

# âœ… Lancer l'Ã©valuation sur les donnÃ©es de test
evaluate_model(model, test_loader)

# âœ… PrÃ©diction sur une image de test
image_path = "/chemin/vers/une/image.jpg"
image = Image.open(image_path)
input_tensor = transform(image).unsqueeze(0).to(device)

model.eval()
with torch.no_grad():
    outputs = model(input_tensor)
    logits = outputs.logits
    preds = (logits > 0).cpu().numpy().flatten()

for i, label in enumerate(labels):
    if preds[i] == 1:
        print(f"âœ… L'image contient un : {label}")

# âœ… Sauvegarder le modÃ¨le en TorchScript
scripted_model = torch.jit.trace(model, torch.randn(1, 3, 224, 224, device=device))
torch.jit.save(scripted_model, "vit_model.pt")
print("âœ… ModÃ¨le sauvegardÃ© en TorchScript !")

